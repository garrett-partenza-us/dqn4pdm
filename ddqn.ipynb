{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2213e38-ec60-4ece-919b-6d85621a88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "65f44d1c-ab6e-4208-9fbe-0ef59bdfa83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "80887762-bb54-44c6-9269-a012d740fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment class\n",
    "class Environment():\n",
    "    \n",
    "    #initialize dataset, a random trajectory, and current cycle\n",
    "    def __init__(self):\n",
    "        self.dataset = pd.read_csv('train.csv')\n",
    "        self.episode = self.get_trajectory(np.random.randint(low=0, high=79, size=1))\n",
    "        self.cycle = 0\n",
    "        \n",
    "    #get random trajectory\n",
    "    def get_trajectory(self, engine_id):\n",
    "        return self.dataset[self.dataset.engine_id==engine_id.item()].health_indicator.to_numpy()\n",
    "    \n",
    "    #reset environment    \n",
    "    def reset(self):\n",
    "        self.cycle = 0\n",
    "        self.episode = self.get_trajectory(np.random.randint(low=0, high=79, size=1))\n",
    "        \n",
    "    #return current state\n",
    "    def get_state(self):\n",
    "        return self.episode[self.cycle]\n",
    "    \n",
    "    #take action\n",
    "    def take_action(self, action):\n",
    "        if action == 0:\n",
    "            if self.cycle+1 == self.episode.size:\n",
    "                res = (-250, None, True)\n",
    "            else:\n",
    "                res = (1, self.episode[self.cycle+1], False)\n",
    "        elif action == 1:\n",
    "            res = (-25, self.episode[self.cycle+1], True)\n",
    "        self.cycle+=1\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e44f1f6e-4c01-4433-9f03-be2e97c64374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition():\n",
    "    \n",
    "    def __init__(self, state, action, state_new, reward):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.state_new = state_new\n",
    "        self.reward = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "09df1af8-1a6b-40d3-a71d-8d71a6693f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn model clas \n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(1,2)\n",
    "        self.lin2 = nn.Linear(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a134ff20-16bc-42f3-a51f-03009d97257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(net, epsilon):\n",
    "    greedy = np.random.choice([True, False], p=[1-epsilon, epsilon])\n",
    "    if greedy:\n",
    "        action = torch.argmax(out, dim=0).item()\n",
    "    else:\n",
    "        action = random.choice([0,1])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9e9837a9-b00e-4d76-a327-392e192e67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0a9c34e8-82c4-47a7-bf1b-55155650df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "exp_replay_size = 128\n",
    "gamma = 0.99\n",
    "epsilon = 0.1\n",
    "target_update_steps = 5\n",
    "num_episodes = 10\n",
    "\n",
    "#begin algorithm\n",
    "QNet = DQN()\n",
    "TNet = DQN()\n",
    "\n",
    "ER = deque(maxlen = exp_replay_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c0596b85-4d36-4a9d-a868-9c3c3a03f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5a949dbd-e073-4cfd-ac74-8d9a5c995d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(num_episodes):\n",
    "    \n",
    "    environment = Environment()\n",
    "    cummulative_reward = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        #observation\n",
    "        state = environment.get_state()\n",
    "        action = get_action(state, epsilon)\n",
    "        state_new, reward, terminated = environment.take_action(action)\n",
    "        \n",
    "        #append to replay buffer\n",
    "        ER.appendleft(Transition(state, action, state_new, reward))\n",
    "        \n",
    "        #update variables\n",
    "        cummulative_reward+=reward\n",
    "        \n",
    "        #train\n",
    "        train()\n",
    "        \n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8821f1-0498-4875-bd45-a8afc8f60c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-rl",
   "language": "python",
   "name": "env-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
