{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2213e38-ec60-4ece-919b-6d85621a88c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import collections\n",
    "import typing\n",
    "from tqdm import tqdm\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f44d1c-ab6e-4208-9fbe-0ef59bdfa83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80887762-bb54-44c6-9269-a012d740fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment class\n",
    "class Environment():\n",
    "    \n",
    "    #initialize dataset, a random trajectory, and current cycle\n",
    "    def __init__(self):\n",
    "        self.dataset = pd.read_csv('train.csv')\n",
    "        self.episode = self.get_trajectory(np.random.randint(low=1, high=79, size=1))\n",
    "        self.cycle = 0\n",
    "        \n",
    "    #get random trajectory\n",
    "    def get_trajectory(self, engine_id):\n",
    "        return self.dataset[self.dataset.engine_id==engine_id.item()].health_indicator.to_numpy()\n",
    "    \n",
    "    #reset environment    \n",
    "    def reset(self):\n",
    "        self.cycle = 0\n",
    "        self.episode = self.get_trajectory(np.random.randint(low=0, high=79, size=1))\n",
    "        \n",
    "    #return current state\n",
    "    def get_state(self):\n",
    "        return torch.tensor([self.episode[self.cycle]], requires_grad=False)\n",
    "    \n",
    "    #take action\n",
    "    def take_action(self, action):\n",
    "        if action == 0:\n",
    "            #failure occurs\n",
    "            if self.cycle+1 == self.episode.size:\n",
    "                res = (None, -1, True)\n",
    "            #continued operation, return 1 and continue episode\n",
    "            else:\n",
    "                res = (self.episode[self.cycle+1], self.episode[self.cycle], False)\n",
    "            #move to next state\n",
    "            self.cycle+=1\n",
    "        elif action == 1:\n",
    "            res = (None, -self.episode[self.cycle], True)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44f1f6e-4c01-4433-9f03-be2e97c64374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition():\n",
    "    \n",
    "    def __init__(self, state, action, state_new, reward, term):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.state_new = state_new\n",
    "        self.reward = reward\n",
    "        self.term = term\n",
    "        \n",
    "class PrioritizedReplayMemory:\n",
    "    \"\"\"Fixed-size buffer to store priority, Experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 batch_size: int,\n",
    "                 buffer_size: int,\n",
    "                 alpha: float = 0.0,\n",
    "                 random_state: np.random.RandomState = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize an ExperienceReplayBuffer object.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        buffer_size (int): maximum size of buffer\n",
    "        batch_size (int): size of each training batch\n",
    "        alpha (float): Strength of prioritized sampling. Default to 0.0 (i.e., uniform sampling).\n",
    "        random_state (np.random.RandomState): random number generator.\n",
    "        \n",
    "        \"\"\"\n",
    "        self._batch_size = batch_size\n",
    "        self._buffer_size = buffer_size\n",
    "        self._buffer_length = 0 # current number of prioritized experience tuples in buffer\n",
    "        self._buffer = np.empty(self._buffer_size, dtype=[(\"priority\", np.float32), (\"transition\", Transition)])\n",
    "        self._alpha = alpha\n",
    "        self._random_state = np.random.RandomState() if random_state is None else random_state\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Current number of prioritized experience tuple stored in buffer.\"\"\"\n",
    "        return self._buffer_length\n",
    "\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        \"\"\"Strength of prioritized sampling.\"\"\"\n",
    "        return self._alpha\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        \"\"\"Number of experience samples per training batch.\"\"\"\n",
    "        return self._batch_size\n",
    "    \n",
    "    @property\n",
    "    def buffer_size(self) -> int:\n",
    "        \"\"\"Maximum number of prioritized experience tuples stored in buffer.\"\"\"\n",
    "        return self._buffer_size\n",
    "\n",
    "    def add(self, transition: Transition) -> None:\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        priority = 1.0 if self.is_empty() else self._buffer[\"priority\"].max()\n",
    "        if self.is_full():\n",
    "            if priority > self._buffer[\"priority\"].min():\n",
    "                idx = self._buffer[\"priority\"].argmin()\n",
    "                self._buffer[idx] = (priority, transition)\n",
    "            else:\n",
    "                pass # low priority experiences should not be included in buffer\n",
    "        else:\n",
    "            self._buffer[self._buffer_length] = (priority, transition)\n",
    "            self._buffer_length += 1\n",
    "\n",
    "    def is_empty(self) -> bool:\n",
    "        \"\"\"True if the buffer is empty; False otherwise.\"\"\"\n",
    "        return self._buffer_length == 0\n",
    "    \n",
    "    def is_full(self) -> bool:\n",
    "        \"\"\"True if the buffer is full; False otherwise.\"\"\"\n",
    "        return self._buffer_length == self._buffer_size\n",
    "    \n",
    "    def sample(self, beta: float) -> typing.Tuple[np.array, np.array, np.array]:\n",
    "        \"\"\"Sample a batch of experiences from memory.\"\"\"\n",
    "        # use sampling scheme to determine which experiences to use for learning\n",
    "        ps = self._buffer[:self._buffer_length][\"priority\"]\n",
    "        sampling_probs = ps**self._alpha / np.sum(ps**self._alpha)\n",
    "        idxs = self._random_state.choice(np.arange(ps.size),\n",
    "                                         size=self._batch_size,\n",
    "                                         replace=True,\n",
    "                                         p=sampling_probs)\n",
    "        \n",
    "        # select the experiences and compute sampling weights\n",
    "        transitions = self._buffer[\"transition\"][idxs]        \n",
    "        weights = (self._buffer_length * sampling_probs[idxs])**-beta\n",
    "        normalized_weights = weights / weights.max()\n",
    "        \n",
    "        return idxs, transitions, normalized_weights\n",
    "\n",
    "    def update_priorities(self, idxs: np.array, priorities: np.array) -> None:\n",
    "        \"\"\"Update the priorities associated with particular experiences.\"\"\"\n",
    "        self._buffer[\"priority\"][idxs] = priorities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09df1af8-1a6b-40d3-a71d-8d71a6693f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn model clas \n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(1,2)\n",
    "        self.lin2 = nn.Linear(2,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a134ff20-16bc-42f3-a51f-03009d97257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(net, state, epsilon):\n",
    "    with torch.no_grad():\n",
    "        greedy = np.random.choice([True, False], p=[1-epsilon, epsilon])\n",
    "        if greedy:\n",
    "            state = torch.tensor([state], dtype=torch.float32)\n",
    "            q_values = net(state)\n",
    "            action = torch.argmax(q_values, dim=0)\n",
    "        else:\n",
    "            action = random.choice([0,1])\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9c34e8-82c4-47a7-bf1b-55155650df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #hyperparameters\n",
    "        self.exp_replay_size = 100000\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 0.2\n",
    "        self.target_update_steps = 10000\n",
    "        self.num_episodes = 5000\n",
    "        self.batch_size = 64\n",
    "        self.train_step_count = 4\n",
    "        self.steps = 0\n",
    "        self.lr = 0.001\n",
    "        self.eps_decay = 5e-7\n",
    "        self.loss_func = nn.HuberLoss()\n",
    "        self.alpha = 0.2\n",
    "        self.episode_count = 0\n",
    "        \n",
    "        #networks\n",
    "        self.QNet = DQN()\n",
    "        self.TNet = DQN()\n",
    "        self.optimizer = torch.optim.Adam(self.QNet.parameters(), lr=self.lr)\n",
    "        \n",
    "        #replay buffer\n",
    "        self.ER = PrioritizedReplayMemory(\n",
    "            batch_size = self.batch_size,\n",
    "            buffer_size = self.exp_replay_size,\n",
    "            alpha = self.alpha\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0596b85-4d36-4a9d-a868-9c3c3a03f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(agent):\n",
    "        \n",
    "    idxs, sample_transitions, sampling_weights = agent.ER.sample(beta=1-np.exp(-agent.lr*agent.episode_count))\n",
    "            \n",
    "    #get batch information\n",
    "    state_batch = [transition.state for transition in sample_transitions]\n",
    "    action_batch = [transition.state for transition in sample_transitions]\n",
    "    reward_batch = [transition.reward for transition in sample_transitions]\n",
    "    state_new = [transition.state_new for transition in sample_transitions]\n",
    "    term_batch = [transition.term for transition in sample_transitions]\n",
    "\n",
    "    state_tensor = torch.tensor(state_batch, dtype=torch.float32, requires_grad=True)\n",
    "    state_tensor = state_tensor.reshape(agent.batch_size, -1)\n",
    "    \n",
    "    policy_preds = agent.QNet(state_tensor)\n",
    "    policy_values = torch.stack([qvalues[idx] for qvalues, idx in zip(policy_preds, map(int, action_batch))])\n",
    "    \n",
    "    state_new_tensor = torch.tensor(state_batch, dtype=torch.float32, requires_grad=True)\n",
    "    state_new_tensor = torch.nan_to_num(state_new_tensor, nan=0.0)\n",
    "    state_new_tensor = state_new_tensor.reshape(agent.batch_size, -1)\n",
    "    target_values = agent.TNet(state_new_tensor)\n",
    "    target_values = torch.max(target_values, dim=1).values\n",
    "    \n",
    "    for idx, is_term in enumerate(term_batch):\n",
    "        target_values[idx] = 0.0 if is_term else target_values[idx]\n",
    "        \n",
    "    target_values = agent.gamma * target_values + torch.tensor(reward_batch, dtype=torch.float32, requires_grad=True)\n",
    "    \n",
    "    deltas = torch.subtract(policy_values, target_values)\n",
    "    \n",
    "    priorities = (deltas.abs()\n",
    "                            .cpu()\n",
    "                            .detach()\n",
    "                            .numpy()\n",
    "                            .flatten())\n",
    "    \n",
    "    agent.ER.update_priorities(idxs, priorities + 1e-5)\n",
    "    \n",
    "    _sampling_weights = (torch.Tensor(sampling_weights).view((-1, 1)))\n",
    "    \n",
    "    loss = torch.mean((deltas * _sampling_weights)**2)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a949dbd-e073-4cfd-ac74-8d9a5c995d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|██████████▋                                                             | 738/5000 [01:05<06:43, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████████▍                                                           | 868/5000 [01:35<31:30,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▏                                                          | 918/5000 [02:03<41:53,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█████████████▉                                                          | 968/5000 [02:34<40:39,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▍                                                        | 1018/5000 [03:09<45:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|███████████████                                                        | 1065/5000 [03:46<51:19,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████▊                                                       | 1117/5000 [04:27<50:43,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████                                                     | 1165/5000 [05:11<1:16:19,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|████████████████▋                                                    | 1213/5000 [05:59<1:05:00,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▍                                                   | 1264/5000 [06:50<1:06:14,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████████████                                                   | 1313/5000 [07:44<1:11:31,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████████████▊                                                  | 1362/5000 [08:39<1:05:48,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████                                                   | 1414/5000 [09:34<58:51,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████████████▏                                                | 1464/5000 [10:30<1:06:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████▊                                                | 1511/5000 [11:24<1:02:25,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████▌                                               | 1560/5000 [12:19<1:02:25,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████▏                                              | 1609/5000 [13:14<1:01:30,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████▊                                              | 1657/5000 [14:08<1:11:38,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████▏                                              | 1706/5000 [15:01<57:30,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▉                                              | 1757/5000 [15:56<57:28,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating target network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|█████████████████████████                                              | 1769/5000 [16:09<29:31,  1.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3020/574855303.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_count\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3020/3097694225.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_transitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#get batch information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3020/4264740849.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, beta)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# use sampling scheme to determine which experiences to use for learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"priority\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msampling_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         idxs = self._random_state.choice(np.arange(ps.size),\n\u001b[1;32m     82\u001b[0m                                          \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "agent.QNet.train()\n",
    "losses = []\n",
    "cummulative_rewards = []\n",
    "\n",
    "for episode in tqdm(range(agent.num_episodes)):\n",
    "    \n",
    "    environment = Environment()\n",
    "    cummulative_reward = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        agent.episode_count+=1\n",
    "        \n",
    "        #observation\n",
    "        state = environment.get_state()\n",
    "        action = get_action(agent.QNet, state, agent.epsilon)\n",
    "        state_new, reward, terminated = environment.take_action(action)\n",
    "        #append to replay buffer\n",
    "        agent.ER.add(Transition(state, action, state_new, reward, terminated))\n",
    "\n",
    "        #update variables\n",
    "        cummulative_reward+=reward\n",
    "                \n",
    "        #increament step count\n",
    "        agent.steps+=1\n",
    "        \n",
    "        #train after every 'train_step_count' steps\n",
    "        if agent.steps%agent.train_step_count==0 and agent.ER.__len__()>agent.batch_size:\n",
    "            agent.optimizer.zero_grad()\n",
    "            loss = optimize(agent)\n",
    "            loss.backward()\n",
    "            agent.optimizer.step()\n",
    "            agent.epsilon=max(0, agent.epsilon-agent.eps_decay)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        #copy weights to target network after every 'target_update_steps' updates\n",
    "        if agent.steps%agent.target_update_steps==0:\n",
    "            print(\"updating target network...\")\n",
    "            agent.TNet.load_state_dict(agent.QNet.state_dict())\n",
    "        \n",
    "        #break when episode is complete\n",
    "        if terminated:\n",
    "            break\n",
    "            \n",
    "    cummulative_rewards.append(cummulative_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3fdefcf-9bd8-46dd-af31-2aff5d128423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot((np.convolve(losses, np.ones(100), 'valid') / 100), label='hubor loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "868dfd75-4c70-450a-b71e-5e8a1c7dfac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW TEST\n",
      "State: 0.3190060254095124, Action: 0, Reward: 0.3190060254095124, New State: 0.3817720048257665, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3817720048257665, Action: 0, Reward: 0.3817720048257665, New State: 0.2858712841150109, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2858712841150109, Action: 0, Reward: 0.2858712841150109, New State: 0.3153212369870291, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3153212369870291, Action: 0, Reward: 0.3153212369870291, New State: 0.2188459153645006, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2188459153645006, Action: 0, Reward: 0.2188459153645006, New State: 0.2611091842247756, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2611091842247756, Action: 0, Reward: 0.2611091842247756, New State: 0.2871951671215816, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2871951671215816, Action: 0, Reward: 0.2871951671215816, New State: 0.2731214983809333, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2731214983809333, Action: 0, Reward: 0.2731214983809333, New State: 0.3182143564695698, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3182143564695698, Action: 0, Reward: 0.3182143564695698, New State: 0.2313676855247014, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2313676855247014, Action: 0, Reward: 0.2313676855247014, New State: 0.300001539099761, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.300001539099761, Action: 0, Reward: 0.300001539099761, New State: 0.305114112023183, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.305114112023183, Action: 0, Reward: 0.305114112023183, New State: 0.3342089299323253, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3342089299323253, Action: 0, Reward: 0.3342089299323253, New State: 0.2758559830371743, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2758559830371743, Action: 0, Reward: 0.2758559830371743, New State: 0.3079733078318281, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3079733078318281, Action: 0, Reward: 0.3079733078318281, New State: 0.2893435614383726, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2893435614383726, Action: 0, Reward: 0.2893435614383726, New State: 0.3585266170432588, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3585266170432588, Action: 0, Reward: 0.3585266170432588, New State: 0.307317831565402, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.307317831565402, Action: 0, Reward: 0.307317831565402, New State: 0.3073436221008072, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3073436221008072, Action: 0, Reward: 0.3073436221008072, New State: 0.2366975453585434, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2366975453585434, Action: 0, Reward: 0.2366975453585434, New State: 0.261188596520564, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.261188596520564, Action: 0, Reward: 0.261188596520564, New State: 0.3025251196223039, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3025251196223039, Action: 0, Reward: 0.3025251196223039, New State: 0.3287382876852801, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3287382876852801, Action: 0, Reward: 0.3287382876852801, New State: 0.2940490138518123, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2940490138518123, Action: 0, Reward: 0.2940490138518123, New State: 0.3183031080554523, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3183031080554523, Action: 0, Reward: 0.3183031080554523, New State: 0.2966368199991387, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2966368199991387, Action: 0, Reward: 0.2966368199991387, New State: 0.2941873608712048, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2941873608712048, Action: 0, Reward: 0.2941873608712048, New State: 0.367179042892761, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.367179042892761, Action: 0, Reward: 0.367179042892761, New State: 0.2786434975086449, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2786434975086449, Action: 0, Reward: 0.2786434975086449, New State: 0.2954362358402775, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2954362358402775, Action: 0, Reward: 0.2954362358402775, New State: 0.2605794642349687, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2605794642349687, Action: 0, Reward: 0.2605794642349687, New State: 0.3016058102342981, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3016058102342981, Action: 0, Reward: 0.3016058102342981, New State: 0.344626779357178, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.344626779357178, Action: 0, Reward: 0.344626779357178, New State: 0.2964953377725747, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2964953377725747, Action: 0, Reward: 0.2964953377725747, New State: 0.3143274426829287, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3143274426829287, Action: 0, Reward: 0.3143274426829287, New State: 0.2688185224714867, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2688185224714867, Action: 0, Reward: 0.2688185224714867, New State: 0.3004345168210349, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3004345168210349, Action: 0, Reward: 0.3004345168210349, New State: 0.3264017786163249, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3264017786163249, Action: 0, Reward: 0.3264017786163249, New State: 0.3467565617733402, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3467565617733402, Action: 0, Reward: 0.3467565617733402, New State: 0.3030505153249878, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3030505153249878, Action: 0, Reward: 0.3030505153249878, New State: 0.3195569183891992, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3195569183891992, Action: 0, Reward: 0.3195569183891992, New State: 0.2757769050068095, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2757769050068095, Action: 0, Reward: 0.2757769050068095, New State: 0.2888581891059498, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2888581891059498, Action: 0, Reward: 0.2888581891059498, New State: 0.2815555708816341, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2815555708816341, Action: 0, Reward: 0.2815555708816341, New State: 0.3349360523855707, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3349360523855707, Action: 0, Reward: 0.3349360523855707, New State: 0.3065981155844757, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3065981155844757, Action: 0, Reward: 0.3065981155844757, New State: 0.3668295266803361, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3668295266803361, Action: 0, Reward: 0.3668295266803361, New State: 0.3214314156995437, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3214314156995437, Action: 0, Reward: 0.3214314156995437, New State: 0.3156984691171313, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3156984691171313, Action: 0, Reward: 0.3156984691171313, New State: 0.323049162831474, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.323049162831474, Action: 0, Reward: 0.323049162831474, New State: 0.3439383736890986, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3439383736890986, Action: 0, Reward: 0.3439383736890986, New State: 0.3444635338162164, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3444635338162164, Action: 0, Reward: 0.3444635338162164, New State: 0.2882072606694363, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2882072606694363, Action: 0, Reward: 0.2882072606694363, New State: 0.3442217160200466, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3442217160200466, Action: 0, Reward: 0.3442217160200466, New State: 0.2983346946147325, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2983346946147325, Action: 0, Reward: 0.2983346946147325, New State: 0.3642354445041106, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3642354445041106, Action: 0, Reward: 0.3642354445041106, New State: 0.3512627018782785, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3512627018782785, Action: 0, Reward: 0.3512627018782785, New State: 0.4081085557312855, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4081085557312855, Action: 0, Reward: 0.4081085557312855, New State: 0.2963599048241316, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2963599048241316, Action: 0, Reward: 0.2963599048241316, New State: 0.3345488216170713, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3345488216170713, Action: 0, Reward: 0.3345488216170713, New State: 0.2972985471007363, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2972985471007363, Action: 0, Reward: 0.2972985471007363, New State: 0.3550881191262382, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3550881191262382, Action: 0, Reward: 0.3550881191262382, New State: 0.3219288986700896, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3219288986700896, Action: 0, Reward: 0.3219288986700896, New State: 0.377298863479439, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.377298863479439, Action: 0, Reward: 0.377298863479439, New State: 0.2937725453594967, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.2937725453594967, Action: 0, Reward: 0.2937725453594967, New State: 0.354958381281855, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.354958381281855, Action: 0, Reward: 0.354958381281855, New State: 0.340090838607427, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.340090838607427, Action: 0, Reward: 0.340090838607427, New State: 0.3727908016809226, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3727908016809226, Action: 0, Reward: 0.3727908016809226, New State: 0.3503271681549593, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3503271681549593, Action: 0, Reward: 0.3503271681549593, New State: 0.3939683142421815, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3939683142421815, Action: 0, Reward: 0.3939683142421815, New State: 0.3552873650881307, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3552873650881307, Action: 0, Reward: 0.3552873650881307, New State: 0.3964712542610971, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3964712542610971, Action: 0, Reward: 0.3964712542610971, New State: 0.4046104857180936, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4046104857180936, Action: 0, Reward: 0.4046104857180936, New State: 0.3673380396143823, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3673380396143823, Action: 0, Reward: 0.3673380396143823, New State: 0.3634989788132906, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3634989788132906, Action: 0, Reward: 0.3634989788132906, New State: 0.3556501873092977, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3556501873092977, Action: 0, Reward: 0.3556501873092977, New State: 0.3824302774132151, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3824302774132151, Action: 0, Reward: 0.3824302774132151, New State: 0.3639528636302693, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3639528636302693, Action: 0, Reward: 0.3639528636302693, New State: 0.3288689980005459, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3288689980005459, Action: 0, Reward: 0.3288689980005459, New State: 0.3261037560779105, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3261037560779105, Action: 0, Reward: 0.3261037560779105, New State: 0.397302457207917, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.397302457207917, Action: 0, Reward: 0.397302457207917, New State: 0.4118660040618574, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4118660040618574, Action: 0, Reward: 0.4118660040618574, New State: 0.3574319140054048, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3574319140054048, Action: 0, Reward: 0.3574319140054048, New State: 0.3961697531134253, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3961697531134253, Action: 0, Reward: 0.3961697531134253, New State: 0.3874349861596252, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3874349861596252, Action: 0, Reward: 0.3874349861596252, New State: 0.3541865561559302, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3541865561559302, Action: 0, Reward: 0.3541865561559302, New State: 0.3871534709105842, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3871534709105842, Action: 0, Reward: 0.3871534709105842, New State: 0.4098871844033074, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4098871844033074, Action: 0, Reward: 0.4098871844033074, New State: 0.3794704254964162, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.3794704254964162, Action: 0, Reward: 0.3794704254964162, New State: 0.4430123477218116, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4430123477218116, Action: 0, Reward: 0.4430123477218116, New State: 0.4114339940137801, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4114339940137801, Action: 0, Reward: 0.4114339940137801, New State: 0.4649847898781871, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4649847898781871, Action: 0, Reward: 0.4649847898781871, New State: 0.4567615821921861, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4567615821921861, Action: 0, Reward: 0.4567615821921861, New State: 0.4322382242389356, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4322382242389356, Action: 0, Reward: 0.4322382242389356, New State: 0.4376506420195099, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4376506420195099, Action: 0, Reward: 0.4376506420195099, New State: 0.4762930501280889, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4762930501280889, Action: 0, Reward: 0.4762930501280889, New State: 0.4588778708764263, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4588778708764263, Action: 0, Reward: 0.4588778708764263, New State: 0.5063051257725074, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5063051257725074, Action: 0, Reward: 0.5063051257725074, New State: 0.4641635781109913, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4641635781109913, Action: 0, Reward: 0.4641635781109913, New State: 0.4736521698984278, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4736521698984278, Action: 0, Reward: 0.4736521698984278, New State: 0.4799546064741463, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4799546064741463, Action: 0, Reward: 0.4799546064741463, New State: 0.4693572636072338, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4693572636072338, Action: 0, Reward: 0.4693572636072338, New State: 0.5126963563246772, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5126963563246772, Action: 0, Reward: 0.5126963563246772, New State: 0.5025291604271065, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5025291604271065, Action: 0, Reward: 0.5025291604271065, New State: 0.4705082748110241, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4705082748110241, Action: 0, Reward: 0.4705082748110241, New State: 0.4547211656711974, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4547211656711974, Action: 0, Reward: 0.4547211656711974, New State: 0.520121064249117, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.520121064249117, Action: 0, Reward: 0.520121064249117, New State: 0.5165555117591235, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5165555117591235, Action: 0, Reward: 0.5165555117591235, New State: 0.5152654578448009, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5152654578448009, Action: 0, Reward: 0.5152654578448009, New State: 0.5545998626843546, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5545998626843546, Action: 0, Reward: 0.5545998626843546, New State: 0.4958649799434159, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.4958649799434159, Action: 0, Reward: 0.4958649799434159, New State: 0.5659154837354735, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5659154837354735, Action: 0, Reward: 0.5659154837354735, New State: 0.5914520084864917, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5914520084864917, Action: 0, Reward: 0.5914520084864917, New State: 0.5670413324050703, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5670413324050703, Action: 0, Reward: 0.5670413324050703, New State: 0.5961855382106968, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5961855382106968, Action: 0, Reward: 0.5961855382106968, New State: 0.5481884637979556, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5481884637979556, Action: 0, Reward: 0.5481884637979556, New State: 0.5982961517976675, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5982961517976675, Action: 0, Reward: 0.5982961517976675, New State: 0.5337002161476155, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.5337002161476155, Action: 0, Reward: 0.5337002161476155, New State: 0.6008424926471608, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6008424926471608, Action: 0, Reward: 0.6008424926471608, New State: 0.6128281543110503, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6128281543110503, Action: 0, Reward: 0.6128281543110503, New State: 0.6637455551722211, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6637455551722211, Action: 0, Reward: 0.6637455551722211, New State: 0.6175779392052271, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6175779392052271, Action: 0, Reward: 0.6175779392052271, New State: 0.6320348851496713, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6320348851496713, Action: 0, Reward: 0.6320348851496713, New State: 0.6824840509475695, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6824840509475695, Action: 0, Reward: 0.6824840509475695, New State: 0.6766770291443417, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6766770291443417, Action: 0, Reward: 0.6766770291443417, New State: 0.6347784095956305, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6347784095956305, Action: 0, Reward: 0.6347784095956305, New State: 0.6544417408995328, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6544417408995328, Action: 0, Reward: 0.6544417408995328, New State: 0.6770133887817226, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6770133887817226, Action: 0, Reward: 0.6770133887817226, New State: 0.6992517636515124, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.6992517636515124, Action: 0, Reward: 0.6992517636515124, New State: 0.7540817418180056, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7540817418180056, Action: 0, Reward: 0.7540817418180056, New State: 0.7006696326323621, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7006696326323621, Action: 0, Reward: 0.7006696326323621, New State: 0.7563463003936065, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7563463003936065, Action: 0, Reward: 0.7563463003936065, New State: 0.7700549171187038, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7700549171187038, Action: 0, Reward: 0.7700549171187038, New State: 0.8214343328329184, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.8214343328329184, Action: 0, Reward: 0.8214343328329184, New State: 0.7420713180688555, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7420713180688555, Action: 0, Reward: 0.7420713180688555, New State: 0.8530745766464889, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.8530745766464889, Action: 0, Reward: 0.8530745766464889, New State: 0.7773579544995588, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "State: 0.7773579544995588, Action: 0, Reward: -1, New State: None, Cummulative Reward: 22.707411602003788\n",
      "\n",
      "NEW TEST\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 137 is out of bounds for axis 0 with size 137",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3020/4074747696.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstate_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3020/3697297038.py\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#return current state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#take action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 137 is out of bounds for axis 0 with size 137"
     ]
    }
   ],
   "source": [
    "agent.QNet.eval()\n",
    "environment = Environment()\n",
    "\n",
    "for test in range(3):\n",
    "    print(\"NEW TEST\")\n",
    "    while True:\n",
    "\n",
    "        #observation\n",
    "        state = environment.get_state()\n",
    "        action = get_action(agent.QNet, state, epsilon=0)\n",
    "        state_new, reward, terminated = environment.take_action(action)\n",
    "\n",
    "        print(\"State: {}, Action: {}, Reward: {}, New State: {}, Cummulative Reward: {}\\n\".format(state[0], action, reward, state_new, cummulative_reward))\n",
    "        #break when episode is complete\n",
    "        if terminated:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1921a-43b8-4979-b939-4cf90e39dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=np.arange(0,1,0.01), y=[agent.QNet(torch.tensor([x]).float())[0].item() for x in np.arange(0,1,0.01)], label='hold')\n",
    "plt.scatter(x=np.arange(0,1,0.01), y=[agent.QNet(torch.tensor([x]).float())[1].item() for x in np.arange(0,1,0.01)], label='repair')\n",
    "plt.xlabel('health indicator', fontsize=18)\n",
    "plt.ylabel('expected reward', fontsize=16)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdc7e81e-d2c0-4197-89a6-b69cd7aef7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([0.2-(5e-7*x) for x in range(500000)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6e766a5-bf60-4eca-a48c-a839416c0b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21fd3fd9-9c08-484a-91e9-d83d39a5b1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'04/07/22'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.today().strftime(\"%m/%d/%y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8724d1c-1691-457b-96f8-ce064b973200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-rl",
   "language": "python",
   "name": "env-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
